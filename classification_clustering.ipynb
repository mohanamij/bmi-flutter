{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification clustering.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohanamij/bmi-flutter/blob/master/classification_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUbqtp_zq4ol"
      },
      "source": [
        "**Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g91GR6-wkMi",
        "outputId": "765d87c0-c07e-4200-b064-64621e7af390"
      },
      "source": [
        "from sklearn import datasets  \n",
        "import matplotlib.pyplot as plt  \n",
        "import pandas as pd    \n",
        "from sklearn.model_selection import train_test_split  \n",
        "from sklearn.naive_bayes import GaussianNB    \n",
        "iris_df = pd.read_csv('wine.csv')\n",
        "iris_df['quality'] = iris_df['quality'].map({\n",
        "        3 : 0,\n",
        "        4 : 0,\n",
        "        5 : 0,\n",
        "        6 : 0,\n",
        "        7 : 1,\n",
        "        8 : 1         \n",
        "})\n",
        "iris_df.head()\n",
        "classes = iris_df.quality\n",
        "array = iris_df.values\n",
        "attributes = array[:,0:11]\n",
        "(train_inputs, test_inputs, train_classes, test_classes) = train_test_split(attributes,classes, train_size=0.9, random_state=42)\n",
        "NB = GaussianNB()  \n",
        "NB.fit(train_inputs,train_classes)\n",
        "y_predict = NB.predict(test_inputs)  \n",
        "print(\"Accuracy :\", NB.score(test_inputs,test_classes)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 78.75 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqxDFt5WqDkc"
      },
      "source": [
        "**Decision tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnONZs6mqJCQ"
      },
      "source": [
        "from sklearn import datasets  \n",
        "import matplotlib.pyplot as plt  \n",
        "import pandas as pd   \n",
        "from sklearn.model_selection import train_test_split     \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "iris_df = pd.read_csv('/content/your_dataset.csv')\n",
        "classes = iris_df.Target\n",
        "array = iris_df.values\n",
        "attributes = array[:,0:10]\n",
        "(train_inputs, test_inputs, train_classes, test_classes) = train_test_split(attributes,classes, train_size=0.5, random_state=1)\n",
        "dtc = DecisionTreeClassifier()\n",
        "dtc.fit(train_inputs, train_classes)\n",
        "dtc.score(test_inputs, test_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysID8LpdpxTf"
      },
      "source": [
        "**MLP Classifier** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyWmOfwLpsZT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split \n",
        "data = pd.read_csv('/content/your_dataset.csv')\n",
        "x=data.values\n",
        "attributes=x[:,0:10]\n",
        "classes=data.target\n",
        "X_train,X_test,y_train, y_test = train_test_split(attributes,classes,test_size = 0.3 , random_state =0)\n",
        "mlp = MLPClassifier()\n",
        "mlp.fit(X_train, y_train)\n",
        "prediction=mlp.predict(X_test)\n",
        "print(\"Accuracy of the MLP classifier :\",(accuracy_score(y_test,prediction))*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VsVvUSgw_EQ"
      },
      "source": [
        "**K means**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrYjVZ5VxBDa"
      },
      "source": [
        "def distance_manhattan(x1,y1,x2,y2):\n",
        "  return abs(x1-x2) + abs(y1-y2)\n",
        "def distance_eucledian(x1,y1,x2,y2):\n",
        "  return ((x2-x1)**2 + (y2-y1)**2)**0.5\n",
        "def distance_metric(method,points):\n",
        "  if method=='manhattan':\n",
        "    return distance_manhattan(points[0][0],points[0][1],points[1][0],points[1][1])\n",
        "  if method=='eucledian':\n",
        "    return distance_eucledian(points[0][0],points[0][1],points[1][0],points[1][1])\n",
        "def update_centroid(points):\n",
        "  x_avg,y_avg = 0,0\n",
        "  for point in points:\n",
        "    x_avg += point[0]\n",
        "    y_avg += point[1]\n",
        "  x_avg,y_avg = x_avg/len(points),y_avg/len(points)\n",
        "  return [x_avg,y_avg]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEEgkg5NxGfk"
      },
      "source": [
        "import copy\n",
        "data_points = [[15, 16],[16, 18.5],[17, 20.2],[16.4, 17.12],[17.23, 18.12],[43, 43],[44.43, 45.212],[45.8, 54.23],[46.313, 43.123],[50.21, 46.3],[99, 99.22],[100.32, 98.123],[100.32, 97.423],[102, 93.23],[102.23, 94.23]]\n",
        "k = 2\n",
        "initial_centroid = [[30,40],[50,60]]\n",
        "prev_result = [[],[]]\n",
        "curr_result = [[],[]]\n",
        "iteration = 1\n",
        "while iteration<10:\n",
        "  for point in data_points:\n",
        "    res1 = distance_metric('manhattan',[initial_centroid[0],point])\n",
        "    res2 = distance_metric('manhattan',[initial_centroid[1],point])\n",
        "    if res1<res2:\n",
        "      curr_result[0].append(point)\n",
        "    else:\n",
        "      curr_result[1].append(point)\n",
        "  print('Iteration',iteration,':',curr_result)\n",
        "  print('Cluster size',len(curr_result))\n",
        "  if curr_result==prev_result:\n",
        "    break\n",
        "  initial_centroid[0] = update_centroid(curr_result[0])\n",
        "  initial_centroid[1] = update_centroid(curr_result[1])\n",
        "  print('Updated centroids',initial_centroid[0],initial_centroid[1])\n",
        "  prev_result = copy.deepcopy(curr_result)\n",
        "  curr_result = [[],[]]\n",
        "  iteration+=1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}